---
title: "ML Models K Means"
author: "Roghan"
date: "5 April 2023"
output: html_document
---

```{r}
library(tidyverse)
library(dplyr)
library(GGally)
library(ggplot2)
```

***Read Data

```{r}
df <- read.csv("./kmeans.csv")
df %>% head
```
```{r}
df$cgpa= as.integer(df$cgpa)
df= df[complete.cases(df),]
```


***Apply machine learning models to find out best model to predict class label created

***Naive Bayes

```{r}
set.seed(1)

sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
```

```{r}
library(e1071)
library(caTools)
library(caret)

set.seed(120) 
classifier_cl <- naiveBayes(class ~ ., data = train)
#classifier_cl

# Predicting on test data'
y_pred <- predict(classifier_cl, newdata = test[-length(test)])

# Confusion Matrix
cm <- table(test$class, y_pred)
cm

# Model Evaluation
confusionMatrix(cm)

```

```{r}
cm
```
```{r}
accuracy= (cm[1,1]+cm[2,2]+cm[3,3])/nrow(test)
```

***Random Forest

```{r}
library(caTools)
library(randomForest)

classifier_RF = randomForest(x = train[-length(train)],
                             y = as.factor(train$class),
                             ntree = 500)
  
classifier_RF

```

```{r}
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test[-length(test)])
  
# Confusion Matrix
cm_rf= table(test$class, y_pred)
cm_rf

```
```{r}
accuracy_rf= (cm_rf[1,1]+cm_rf[2,2]+cm_rf[3,3])/nrow(test)
```

```{r}
# Plotting model
plot(classifier_RF)
  
# Importance plot
importance(classifier_RF)
  
# Variable importance plot
varImpPlot(classifier_RF)
```

***Decision Tree

```{r}
library(party)

classifier_dt<- ctree(as.factor(class) ~ ., train)
plot(model)
```

```{r}
prediction <- predict(classifier_dt, test[-length(test)])
cm_dt <- table(test$class, prediction)
cm_dt

```

```{r}
accuracy_dt= (cm_dt[1,1]+cm_dt[2,2]+cm_dt[3,3])/nrow(test)
```


```{r}
print(paste("Naive Bayes: ", accuracy))
print(paste("Random Forest: ", accuracy_rf))
print(paste("Decision Trees: ", accuracy_dt))

#Comparing the accuracies of the Naive Bayes, Random Forest and SVM we arrive at the 
#conclusion that Random Forest performs the best with ~93.93% accuracy
```

***Testing model accuracy from survey

```{r}
survey <- read.csv("./survey-main.csv")
survey %>% head
```

```{r}
colnames(survey) <- c('id', 'sex', 'yr', 'age', 'cgpa', 'bdevice', 'adevice', 'btime', 'atime', 'bdevstudy',      'adevstudy', 'bconc', 'aconc', 'bbed', 'abed', 'baffbed', 'aaffbed',
    'btire', 'atire', 'socdist', 'isolate', 'personality', 'lazy', 'boredom', 'psycho',                       'afford','unhealthy', 'covidstress', 'devicegpa', 'assgn', 'f2f', 'quiz','class')
```

```{r}
check= survey$class
survey= survey[-length(survey)]
```

```{r}
cols <- colnames(survey)[10:ncol(survey)]
for(i in cols){
  
  for (row in 1:nrow(survey)) {
    v <- trimws(survey[row, i])
    
    if(v=="Strongly Disagree"){
      curr= 0
    }
    else if (v=="Disagree"){
      curr= 1
    }
    else if (v=="Uncertain"){
      curr= 2
    }
    else if (v=="Agree"){
      curr= 3
    }
    else if (v=="Strongly Agree"){
      curr= 4
    }
    survey[row, i] = curr
  }
}
```

```{r}
survey$btime[survey$btime=="+12"]<-"12+"
survey$atime[survey$atime=="+12"]<-"12+"

```

```{r}
survey
```

***Encoding

```{r}
lab= c("1-3 ","3-6","6-9","9-12","12+")
val= c(0,1,2,3,4)


for (x in 1:length(lab)){
  survey$btime[survey$btime==lab[x]]<-val[x]
  survey$atime[survey$atime==lab[x]]<-val[x]
}

lab= c("Female","Male")
val= c(0,1)


for (x in 1:length(lab)){
  survey$sex[survey$sex==lab[x]]<-val[x]
}

lab= c("First/Freshman","Second/ Sophomore", "Third/Junior", "Fourth/Senior", "Other")
val= c(0,1,2,3,4)


for (x in 1:length(lab)){
  survey$yr[survey$yr==lab[x]]<-val[x]
}

lab= c("18-24","25-30", "+30")
val= c(0,1,2)


for (x in 1:length(lab)){
  survey$age[survey$age==lab[x]]<-val[x]
}

lab= c("60-69","70-79", "80-89", "+90")
val= c(0,1,2, 3)


for (x in 1:length(lab)){
  survey$cgpa[survey$cgpa==lab[x]]<-val[x]
}

lab= c("Laptop", "Mobile phone", "I pad/ Tablet", "Personal Computer", "Other")
val= c(0,1,2,3,4)


for (x in 1:length(lab)){
  survey$bdevice[survey$bdevice==lab[x]]<-val[x]
  survey$adevice[survey$adevice==lab[x]]<-val[x]
}

survey
```
```{r}
cols= colnames(survey)[8:19]
cols
```


```{r}
i=1
c=1

newcols= c("time", "devstudy", "conc", "bed", "affbed", "tire")

while(i!=13){
  final= c()
  
  for (row in 1:nrow(survey)) {
    v1 <- as.numeric(survey[row, cols[i]])
    v2 <- as.numeric(survey[row, cols[i+1]])
    
    if (i==7){
      final= append(final, v1-v2)
    }
    else{
      final= append(final, v2-v1)
    }
  }

  i= i+2
  survey[,newcols[c]] <- final
  c= c+1
}
```
```{r}
survey
```
```{r}
for(x in colnames(survey)[8:ncol(survey)]){
  survey[,x]= as.numeric(survey[,x])
}

```

```{r}
newdf= data.frame(devuse.score= survey$time + survey$devstudy + survey$conc)
newdf= cbind(newdf, sleep.score= survey$bed + survey$affbed + survey$tire)
newdf= cbind(newdf, social.score= survey$socdist + survey$isolate + survey$personality + survey$lazy)
newdf= cbind(newdf, psych.score= survey$boredom + survey$psycho + survey$afford + survey$unhealthy + survey$covidstress)
newdf= cbind(newdf, acad.score= survey$devicegpa + survey$assgn + survey$f2f + survey$quiz)

```
```{r}
newdf
```

***Adding class label to main dataframe

```{r}
survey= survey[, c(2:7)]
survey
```

```{r}
survey= cbind(survey, newdf)
```

```{r}
for (x in 1:ncol(survey)){
  survey[, x]= as.integer(survey[, x])
}
survey
```

```{r}
y_pred <- predict(classifier_RF, newdata = survey)

# Confusion Matrix
cm_test <- table(check, y_pred)
cm_test

# Model Evaluation
confusionMatrix(cm_test)
```
```{r}
accuracy_test= (cm_test[1,1]+cm_test[2,2]+cm_test[3,3])/nrow(survey)
accuracy_test
```

***Voting Classifier

```{r}
optimized= c()
for (x in 1:nrow(survey)){
  arr= c(0,0,0)
  
  pred_dt= as.integer(predict(classifier_dt, survey[x, ]))
  pred_RF= as.integer(predict(classifier_RF, survey[x, ]))
  pred_cl= as.integer(predict(classifier_cl, survey[x, ]))
  
  arr[pred_dt] = arr[pred_dt] + 1
  arr[pred_RF] = arr[pred_RF] + 1
  arr[pred_cl] = arr[pred_cl] + 1
  
  flag= 0
  
  for (j in 1:length(arr)){
    if (arr[j]==2 || arr[j]==3){
      optimized= append(optimized, j)
    }
    else{
      flag = flag + 1
    }
  }
  
  if (flag==3){
    optimized= append(optimized, pred_RF)
  }
  

}

optimized
```
```{r}
# Confusion Matrix
cm_vote <- table(check, optimized)
cm_vote

# Model Evaluation
confusionMatrix(cm_vote)
```
```{r}
accuracy_vote= (cm_vote[1,1]+cm_vote[2,2]+cm_vote[3,3])/nrow(survey)
accuracy_vote

#Voting Classifier Increases the accuracy from ~93.44% to ~95.08%
```